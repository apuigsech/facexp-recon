{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1e1911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelBinarizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import MobileNetV2, ResNet50\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de229ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorBoard to monitor training activity on realtime.\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f35919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset images into the DataFrame.\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for emotion in os.listdir('dataset'):\n",
    "    if os.path.isdir(f'dataset/{emotion}'):\n",
    "        for image_filename in os.listdir(f'dataset/{emotion}'):\n",
    "            image = Image.open(f'dataset/{emotion}/{image_filename}')\n",
    "            pixels = np.array(image).astype(float)\n",
    "            dataset.append((pixels, emotion))\n",
    "\n",
    "df = pd.DataFrame(dataset, columns=['pixels', 'emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659ce47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizacion of the data.\n",
    "\n",
    "X = np.array([MinMaxScaler().fit_transform(e) for e in df['pixels']])\n",
    "Y = LabelBinarizer().fit_transform(df['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54daff95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and test data.\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a009e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributes for input (images width, high and channel) and output (number of labels).\n",
    "\n",
    "_, IMAGE_WIDTH, IMAGE_HEIGHT = X.shape\n",
    "_, NUM_LABELS = Y.shape\n",
    "\n",
    "NUM_CHANNELS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301414cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Convolutional model.\n",
    "\n",
    "modelConv = Sequential([\n",
    "    Conv2D(32, (3,3), padding=\"Same\", activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, NUM_CHANNELS)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(32, (5,5), padding=\"Same\", activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Dropout(0.5),\n",
    "    Conv2D(64, (3,3), padding=\"Same\", activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (5,5), padding=\"Same\", activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Dropout(0.5),\n",
    "    Conv2D(128, (3,3), padding=\"Same\", activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(128, (5,5), padding=\"Same\", activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Dropout(0.5),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(NUM_LABELS, activation='softmax'),\n",
    "])\n",
    "\n",
    "modelConv.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3616ff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the convolutional model.\n",
    "\n",
    "modelConv.fit(X_train, Y_train, batch_size=32, epochs=50, validation_data=(X_test, Y_test), callbacks=[TensorBoard(log_dir=\"logs/modelConv\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4428f1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "score, acc = modelConv.evaluate(X_test, Y_test, batch_size=100)\n",
    "print('Test score:', score)\n",
    "print(\"Test accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351b4142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset images into the DataFrame and convert into RGB (required by MobileNetV2)\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for emotion in os.listdir('dataset'):\n",
    "    if os.path.isdir(f'dataset/{emotion}'):\n",
    "        for image_filename in os.listdir(f'dataset/{emotion}'):\n",
    "            image = Image.open(f'dataset/{emotion}/{image_filename}').resize((128, 128), resample=Image.Resampling.LANCZOS).convert(\"RGB\")\n",
    "            pixels = np.array(image).astype(float)\n",
    "            dataset.append((pixels, emotion))\n",
    "\n",
    "df = pd.DataFrame(dataset, columns=['pixels', 'emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3c733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizacion of the data.\n",
    "\n",
    "X = np.array((df['pixels']/255).values.tolist())\n",
    "Y = LabelBinarizer().fit_transform(df['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240bdfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and test data.\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d97667",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385a86b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributes for input (images width, high and channel) and output (number of labels).\n",
    "\n",
    "_, IMAGE_WIDTH, IMAGE_HEIGHT, NUM_CHANNELS = X.shape\n",
    "_, NUM_LABELS = Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93385b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MobileNetV2 based model.\n",
    "\n",
    "base_model = MobileNetV2(input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, NUM_CHANNELS),\n",
    "                         include_top=False,\n",
    "                         weights='imagenet')\n",
    "\n",
    "#base_model.trainable = False\n",
    "\n",
    "modelMobNet = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(NUM_LABELS, activation='softmax'),\n",
    "])\n",
    "\n",
    "modelMobNet.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df59856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the MobileNetV2 based model.\n",
    "\n",
    "modelMobNet.fit(X_train, Y_train, batch_size=32, epochs=50,  validation_data=(X_test, Y_test), callbacks=[TensorBoard(log_dir=\"logs/modelMobNet\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa8fbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "score, acc = modelMobNet.evaluate(X_test, Y_test, batch_size=100)\n",
    "print('Test score:', score)\n",
    "print(\"Test accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a13425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ResNet50 based model.\n",
    "\n",
    "base_model = model = ResNet50(input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, NUM_CHANNELS),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "#base_model.trainable = False\n",
    "\n",
    "modelResNet = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(NUM_LABELS, activation='softmax'),\n",
    "])\n",
    "\n",
    "modelResNet.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d350bd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the ResNet50 based model.\n",
    "\n",
    "modelResNet.fit(X_train, Y_train, batch_size=32, epochs=50,  validation_data=(X_test, Y_test), callbacks=[TensorBoard(log_dir=\"logs/modelResNet\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788fb864",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
