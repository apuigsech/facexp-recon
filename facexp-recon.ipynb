{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1e1911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelBinarizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import MobileNetV2, ResNet50\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29279e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of emotions on the dataset we want to include (using comments -#- to exlcude).\n",
    "\n",
    "EMOTIONS=[\n",
    "    #'angry',\n",
    "    #'disgust',\n",
    "    #'fear',\n",
    "    'happy',\n",
    "    'neutral',\n",
    "    'sad',\n",
    "    'surprise',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f35919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset images into the DataFrame.\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for emotion in EMOTIONS:\n",
    "    if os.path.isdir(f'dataset/{emotion}'):\n",
    "        for image_filename in os.listdir(f'dataset/{emotion}'):\n",
    "            image = Image.open(f'dataset/{emotion}/{image_filename}')\n",
    "            pixels = np.array(image).astype(float)\n",
    "            dataset.append((pixels, emotion))\n",
    "\n",
    "df = pd.DataFrame(dataset, columns=['pixels', 'emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659ce47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizacion of the data.\n",
    "\n",
    "X = np.array([MinMaxScaler().fit_transform(e) for e in df['pixels']])\n",
    "Y = LabelBinarizer().fit_transform(df['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54daff95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and test data.\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a009e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributes for input (images width, high and channel) and output (number of labels).\n",
    "\n",
    "_, IMAGE_WIDTH, IMAGE_HEIGHT = X.shape\n",
    "_, NUM_LABELS = Y.shape\n",
    "\n",
    "NUM_CHANNELS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301414cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Convolutional model.\n",
    "\n",
    "modelConv = Sequential([\n",
    "    Conv2D(32, (3,3), padding=\"Same\", activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, NUM_CHANNELS)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(32, (5,5), padding=\"Same\", activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Dropout(0.5),\n",
    "    Conv2D(64, (3,3), padding=\"Same\", activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (5,5), padding=\"Same\", activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Dropout(0.5),\n",
    "    Conv2D(128, (3,3), padding=\"Same\", activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(128, (5,5), padding=\"Same\", activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Dropout(0.5),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(NUM_LABELS, activation='softmax'),\n",
    "])\n",
    "\n",
    "modelConv.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3616ff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the convolutional model.\n",
    "\n",
    "historyConv = modelConv.fit(X_train, Y_train, \n",
    "                            batch_size=32, epochs=25, \n",
    "                            validation_data=(X_test, Y_test), \n",
    "                            callbacks=[TensorBoard(log_dir=\"logs/modelConv\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4428f1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "score, acc = modelConv.evaluate(X_test, Y_test, batch_size=100)\n",
    "print('Test score:', score)\n",
    "print(\"Test accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351b4142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset images into the DataFrame and convert into RGB (required by MobileNetV2)\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for emotion in EMOTIONS:\n",
    "    if os.path.isdir(f'dataset/{emotion}'):\n",
    "        for image_filename in os.listdir(f'dataset/{emotion}'):\n",
    "            image = Image.open(f'dataset/{emotion}/{image_filename}').resize((128, 128), resample=Image.Resampling.LANCZOS).convert(\"RGB\")\n",
    "            pixels = np.array(image).astype(float)\n",
    "            dataset.append((pixels, emotion))\n",
    "\n",
    "df = pd.DataFrame(dataset, columns=['pixels', 'emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3c733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizacion of the data.\n",
    "\n",
    "X = np.array((df['pixels']/255).values.tolist())\n",
    "Y = LabelBinarizer().fit_transform(df['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240bdfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and test data.\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385a86b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributes for input (images width, high and channel) and output (number of labels).\n",
    "\n",
    "_, IMAGE_WIDTH, IMAGE_HEIGHT, NUM_CHANNELS = X.shape\n",
    "_, NUM_LABELS = Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93385b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MobileNetV2 based model.\n",
    "\n",
    "base_model = MobileNetV2(input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, NUM_CHANNELS),\n",
    "                         include_top=False,\n",
    "                         weights='imagenet')\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "modelMobNet = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(NUM_LABELS, activation='softmax'),\n",
    "])\n",
    "\n",
    "modelMobNet.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df59856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the MobileNetV2 based model.\n",
    "\n",
    "historyMobNet = modelMobNet.fit(X_train, Y_train,\n",
    "                                batch_size=32, epochs=25, \n",
    "                                validation_data=(X_test, Y_test),\n",
    "                                callbacks=[TensorBoard(log_dir=\"logs/modelMobNet\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa8fbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "score, acc = modelMobNet.evaluate(X_test, Y_test, batch_size=100)\n",
    "print('Test score:', score)\n",
    "print(\"Test accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a13425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ResNet50 based model.\n",
    "\n",
    "base_model = model = ResNet50(input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, NUM_CHANNELS),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "modelResNet = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(NUM_LABELS, activation='softmax')\n",
    "])\n",
    "\n",
    "modelResNet.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d350bd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the ResNet50 based model.\n",
    "\n",
    "historyResNet = modelResNet.fit(X_train, Y_train,\n",
    "                                batch_size=32, epochs=25, \n",
    "                                validation_data=(X_test, Y_test),\n",
    "                                callbacks=[TensorBoard(log_dir=\"logs/modelResNet\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8ef91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show lost and accuracy for train and test for the convolutional network.\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 6))\n",
    "axs[0].plot(historyConv.history['loss'])\n",
    "axs[0].plot(historyConv.history['val_loss'])\n",
    "axs[1].plot(historyConv.history['accuracy'])\n",
    "axs[1].plot(historyConv.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3dd982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show lost and accuracy for train and test for the MobileNetv2 based network.\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 6))\n",
    "axs[0].plot(historyMobNet.history['loss'])\n",
    "axs[0].plot(historyMobNet.history['val_loss'])\n",
    "axs[1].plot(historyMobNet.history['accuracy'])\n",
    "axs[1].plot(historyMobNet.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14efa381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show lost and accuracy for train and test for the ResNet50 based network.\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 6))\n",
    "axs[0].plot(historyResNet.history['loss'])\n",
    "axs[0].plot(historyResNet.history['val_loss'])\n",
    "axs[1].plot(historyResNet.history['accuracy'])\n",
    "axs[1].plot(historyResNet.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1549cc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained models\n",
    "\n",
    "modelConv.save('models/modelConv.h5')\n",
    "modelMobNet.save('models/modelMobNet.h5')\n",
    "modelResNet.save('models/modelResNet.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
